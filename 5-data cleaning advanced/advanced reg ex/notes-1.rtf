{\rtf1\ansi\ansicpg1252\cocoartf2511
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;\f1\froman\fcharset0 Times-Roman;\f2\froman\fcharset0 Times-Italic;
\f3\fnil\fcharset0 Menlo-Regular;}
{\colortbl;\red255\green255\blue255;\red41\green46\blue57;\red255\green255\blue255;\red183\green13\blue60;
\red247\green237\blue240;\red47\green196\blue135;}
{\*\expandedcolortbl;;\cssrgb\c21176\c23922\c28627;\cssrgb\c100000\c100000\c100000;\cssrgb\c77647\c14118\c30196;
\cssrgb\c97647\c94510\c95294;\cssrgb\c20000\c80000\c60000;}
{\*\listtable{\list\listtemplateid1\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}.}{\leveltext\leveltemplateid1\'02\'00.;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid1}}
{\*\listoverridetable{\listoverride\listid1\listoverridecount0\ls1}}
\paperw11900\paperh16840\margl1440\margr1440\vieww28600\viewh18000\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs28 \cf0 \'97 pattern = r"[Pp]ython"\
python_counts = titles.str.contains(pattern).sum()\
print(python_counts)\
												         iki kod ayni seyi yapiyor\
pattern = r"python"\
python_counts = titles.str.contains(pattern, flags=re.I).sum()\
print(python_counts)\
\
\'97hn_sql = hn[hn['title'].str.contains(r"\\w+SQL", flags=re.I)].copy()\
hn_sql['flavor']=hn_sql['title'].str.extract(r"(\\w+SQL)", re.I)\
hn_sql['flavor']=hn_sql['flavor'].str.lower()\
sql_pivot=hn_sql.pivot_table(index='flavor',values='num_comments',aggfunc='mean')\
\
\'97 pattern = r"[Pp]ython ([\\d\\.]+)"\
\
py_versions = titles.str.extract(pattern)\
py_versions_freq = dict(py_versions.value_counts())\
\
\'97 def first_10_matches(pattern):\
    """\
    Return the first 10 story titles that match\
    the provided regular expression\
    """\
    all_matches = titles[titles.str.contains(pattern)]\
    first_10 = all_matches.head(10)\
    return first_10\
\
pattern = r"\\b[Cc]\\b[^.+]\'94				c ya da C olacak ama C++ veya C.E.O olmayacak\
first_ten = first_10_matches(pattern)\
\
\'97 pattern = r"(?<!Series\\s)\\b[Cc]\\b(?![\\+\\.])"		oncesinde \'91Series \'91 (sonda bosluk var) sonras\uc0\u305 nda da + ve . olmayacak yani \'91Series C\'92 ve C++ veya C.E.O olmuyor\
c_mentions = titles.str.contains(pattern).sum()\
\
\'97 pattern = r"\\b(\\w+)\\s\\1\\b"			\'85 problem problem \'85/ \'85 week week \'85   yani ayni sozcuk ikilediginde\
\
repeated_words = titles[titles.str.contains(pattern)]		\
\
\'97string = "aBcDEfGHIj"\
print(re.sub(r"[A-Z]", "-", string))\
a-c--f---j\
\
\'97 sql_variations = pd.Series(["SQL", "Sql", "sql"])\
\
sql_uniform = sql_variations.str.replace(r"sql", "SQL", flags=re.I)\
print(sql_uniform)\
\
0    SQL\
1    SQL\
2    SQL\
dtype: object\
\
\'97email_variations = pd.Series(['email', 'Email', 'e Mail',\
                        'e mail', 'E-mail', 'e-mail',\
                        'eMail', 'E-Mail', 'EMAIL'])\
\
pattern = r"e[\\-\\s]?mail"\
email_uniform = email_variations.str.replace(pattern, "email", flags=re.I)\
titles_clean = titles.str.replace(pattern, "email", flags=re.I)\
\
\'97 test_urls = pd.Series([\
 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429',\
 'http://www.interactivedynamicvideo.com/',\
 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0',\
 'http://evonomics.com/advertising-cannot-maintain-internet-heres-solution/',\
 'HTTPS://github.com/keppel/pinn',\
 'Http://phys.org/news/2015-09-scale-solar-youve.html',\
 'https://iot.seeed.cc',\
 'http://www.bfilipek.com/2016/04/custom-deleters-for-c-smart-pointers.html',\
 'http://beta.crowdfireapp.com/?beta=agnipath',\
 'https://www.valid.ly?param',\
 'http://css-cursor.techstream.org'\
])\
\
pattern = r"https?://([\\w\\-\\.]+)"\
\
test_urls_clean = test_urls.str.extract(pattern, flags=re.I)\
domains = hn['url'].str.extract(pattern, flags=re.I)\
top_domains = domains.value_counts().head(5)\
\
\'97 pattern = r"(https?)://([\\w\\.\\-]+)/?(.*)"			herbir parantez URL nin bir ismini temsil ediyor\
\
test_url_parts = test_urls.str.extract(pattern, flags=re.I)\
url_parts = hn['url'].str.extract(pattern, flags=re.I)		        \
\
\'97 created_at = hn['created_at'].head()\
\
pattern = r"(.+) (.+)"\
dates_times = created_at.str.extract(pattern)\
print(dates_times)\
\
_          0      1\
0   8/4/2016  11:52\
1  1/26/2016  19:30\
2  6/23/2016  22:20\
3  6/17/2016   0:01\
4  9/30/2015   4:12\
\
\'97 pattern = r"(?P<date>.+) (?P<time>.+)"\
dates_times = created_at.str.extract(pattern)\
print(dates_times)\
\
_       date   time\
0   8/4/2016  11:52\
1  1/26/2016  19:30\
2  6/23/2016  22:20\
3  6/17/2016   0:01\
4  9/30/2015   4:12\
\
\'97 pattern = r"(?P<protocol>https?)://(?P<domain>[\\w\\.\\-]+)/?(?P<path>.*)"\
url_parts = hn['url'].str.extract(pattern, flags=re.I)\
\
\'97 
\f1 \cf2 \cb3 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 As we learned in the previous mission, to\'a0
\f2\i extract
\f1\i0 \'a0those mentions, we need to do two things:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl840\partightenfactor0
\ls1\ilvl0
\fs42 \cf2 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1.	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Use the\'a0{\field{\*\fldinst{HYPERLINK "http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.extract.html"}}{\fldrslt 
\f3\fs35\fsmilli17850 \cf4 \cb5 \strokec4 Series.str.extract()
\f1\fs42 \cf6 \cb3 \strokec6 \'a0method}}.\cb1 \
\ls1\ilvl0\cb3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2.	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Use a regex capture group.\cb1 \
\pard\tx566\pardeftab720\sl840\partightenfactor0
\cf2  \
\'97\
}